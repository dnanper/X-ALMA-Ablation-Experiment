# Ablation Experiment

ThÆ° má»¥c nÃ y chá»©a cÃ¡c script Ä‘á»ƒ cháº¡y thÃ­ nghiá»‡m ablation study cho X-ALMA model.

## ğŸ“ Cáº¥u trÃºc

```
ablation/
â”œâ”€â”€ runs/
â”‚   â”œâ”€â”€ inference.py      # Script dá»‹ch vÄƒn báº£n báº±ng X-ALMA
â”‚   â”œâ”€â”€ evaluation.py     # Script tÃ­nh BLEU vÃ  COMET-22
â”‚   â””â”€â”€ requirements.txt  # Dependencies cáº§n thiáº¿t
â””â”€â”€ results/              # ThÆ° má»¥c chá»©a káº¿t quáº£ Ä‘áº§u ra
```

## ğŸ”§ CÃ i Ä‘áº·t

### 1. CÃ i Ä‘áº·t dependencies

```bash
cd ablation/runs
pip install -r requirements.txt
```

### 2. YÃªu cáº§u há»‡ thá»‘ng

- **GPU**: Cáº§n GPU vá»›i Ã­t nháº¥t 16GB VRAM (Ä‘á»ƒ load model 13B vá»›i 4-bit quantization)
- **Python**: 3.8+
- **CUDA**: ÄÆ°á»£c cÃ i Ä‘áº·t vÃ  hoáº¡t Ä‘á»™ng vá»›i PyTorch

## ğŸš€ CÃ¡ch cháº¡y

### BÆ°á»›c 1: Inference (Dá»‹ch vÄƒn báº£n)

File `inference.py` sáº½:

- Load model X-ALMA vá»›i adapter
- Dá»‹ch test set tá»« WMT23
- LÆ°u káº¿t quáº£ vÃ o thÆ° má»¥c `outputs/`

**Chá»‰nh sá»­a tham sá»‘ trong `inference.py`:**

```python
load_and_translate(
    base_model_path="haoranxu/ALMA-13B-Pretrain",  # Base model
    adapter_path="haoranxu/X-ALMA-13B-Group1",      # Adapter path
    output_dir="./outputs/pretrained",               # ThÆ° má»¥c Ä‘áº§u ra
    lang_pair="de-en",                               # Cáº·p ngÃ´n ngá»¯
    max_samples=None,                                # None = dá»‹ch háº¿t, hoáº·c sá»‘ nguyÃªn
    use_5shot=True,                                  # DÃ¹ng 5-shot prompting
    chat_style=True                                  # DÃ¹ng chat template
)
```

**Cháº¡y inference:**

```bash
cd ablation/runs
python inference.py
```

**CÃ¡c cáº·p ngÃ´n ngá»¯ Ä‘Æ°á»£c há»— trá»£:**

- `cs-en`, `en-cs` (Czech â†” English)
- `de-en`, `en-de` (German â†” English)
- `is-en`, `en-is` (Icelandic â†” English)
- `ru-en`, `en-ru` (Russian â†” English)
- `zh-en`, `en-zh` (Chinese â†” English)

**Output files:**

- `test-{src}-{tgt}.txt` - Báº£n dá»‹ch
- `test-{lang_pair}.ref` - Reference (ground truth)
- `test-{lang_pair}.src` - Source text
- `test-{lang_pair}.debug.txt` - Raw model output (Ä‘á»ƒ debug)

### BÆ°á»›c 2: Evaluation (TÃ­nh metrics)

File `evaluation.py` sáº½ tÃ­nh:

- **BLEU score**: Metric Ä‘Ã¡nh giÃ¡ n-gram overlap
- **COMET-22**: Neural metric (primary metric trong ALMA paper)

**Chá»‰nh sá»­a Ä‘Æ°á»ng dáº«n trong `evaluation.py`:**

```python
# Thay Ä‘á»•i Ä‘Æ°á»ng dáº«n Ä‘áº¿n output files cá»§a báº¡n
pretrained_bleu = calculate_bleu(
    f"./outputs/pretrained/test-{lang_pair}.txt",  # Báº£n dá»‹ch
    f"./outputs/pretrained/test-{lang_pair}.ref"   # Reference
)

pretrained_comet = calculate_comet(
    f"./outputs/pretrained/test-{lang_pair}.src",  # Source
    f"./outputs/pretrained/test-{lang_pair}.txt",  # Báº£n dá»‹ch
    f"./outputs/pretrained/test-{lang_pair}.ref",  # Reference
    comet_model_path
)
```

**Cháº¡y evaluation:**

```bash
cd ablation/runs
python evaluation.py
```

**Output máº«u:**

```
==============================================================
EVALUATION METRICS (BLEU + COMET-22)
==============================================================

DE-EN:
------------------------------------------------------------
  BLEU:
  Pretrained:   28.45

  COMET-22:
  Pretrained:   0.8234
```

## ğŸ“Š Káº¿t quáº£

Káº¿t quáº£ sáº½ Ä‘Æ°á»£c lÆ°u trong `ablation/results/`:

- Screenshots cÃ¡c metrics
- Báº£ng so sÃ¡nh giá»¯a cÃ¡c variants

## ğŸ’¡ Tips

### Debug khi model khÃ´ng dá»‹ch Ä‘Ãºng:

1. Kiá»ƒm tra file `.debug.txt` Ä‘á»ƒ xem raw output cá»§a model
2. Kiá»ƒm tra sá»‘ dÃ²ng giá»¯a hypothesis vÃ  reference cÃ³ khá»›p khÃ´ng
3. Thá»­ giáº£m `max_samples` Ä‘á»ƒ test nhanh hÆ¡n

### Tá»‘i Æ°u memory:

- Giáº£m `batch_size` trong `calculate_comet()` náº¿u bá»‹ OOM
- DÃ¹ng `max_samples` Ä‘á»ƒ test trÃªn subset nhá» trÆ°á»›c

### Thay Ä‘á»•i model/adapter:

```python
# VÃ­ dá»¥: test vá»›i base model khÃ¡c
load_and_translate(
    base_model_path="meta-llama/Llama-2-13b-hf",
    adapter_path="path/to/your/adapter",
    output_dir="./outputs/your_experiment",
    lang_pair="en-zh"
)
```

## ğŸ” So sÃ¡nh vá»›i thÃ­ nghiá»‡m gá»‘c

Scripts nÃ y replicate pipeline tá»« `run_llmmt.py` vÃ  `evals/` Ä‘á»ƒ:

- DÃ¹ng Ä‘Ãºng prompt format (5-shot tá»« `Filtered-5-shot/`)
- DÃ¹ng Ä‘Ãºng chat template
- Post-process output giá»‘ng há»‡t nhÆ° code gá»‘c

## ğŸ“ Notes

- **COMET-22 lÃ  metric chÃ­nh** Ä‘Æ°á»£c dÃ¹ng trong ALMA paper
- Model sáº½ tá»± Ä‘á»™ng download láº§n Ä‘áº§u (khoáº£ng 1-2GB)
- Inference trÃªn full test set máº¥t khoáº£ng 30-60 phÃºt tÃ¹y GPU

## â“ Troubleshooting

### Lá»—i: "Line count mismatch"

â†’ Model sinh ra output rá»—ng cho má»™t sá»‘ cÃ¢u. Kiá»ƒm tra `.debug.txt` vÃ  cÃ³ thá»ƒ cáº§n Ä‘iá»u chá»‰nh prompt.

### Lá»—i: "CUDA out of memory"

â†’ Giáº£m `max_length`, `max_new_tokens` hoáº·c dÃ¹ng GPU lá»›n hÆ¡n.

### Lá»—i: "5-shot file not found"

â†’ Äáº£m báº£o thÆ° má»¥c `human_written_data/Filtered-5-shot/` tá»“n táº¡i vá»›i file `shots.{lang_pair}.json`

---

**Happy experimenting! ğŸš€**
