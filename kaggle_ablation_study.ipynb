{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f698bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/dnanper/X-ALMA-Ablation-Experiment.git\n",
    "%cd X-ALMA-Ablation-Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4b72ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!bash install_alma.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31f7d6d",
   "metadata": {},
   "source": [
    "## Experiment 1: Unpretrained Base (Measure pretrain contribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621153bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run with unpretrained base (Llama-2-13b-hf)\n",
    "!accelerate launch --config_file configs/deepspeed_eval_config_bf16.yaml \\\n",
    "    run_llmmt.py \\\n",
    "    --model_name_or_path haoranxu/X-ALMA-13B-Group5 \\\n",
    "    --custom_base_model meta-llama/Llama-2-13b-hf \\\n",
    "    --do_predict \\\n",
    "    --low_cpu_mem_usage \\\n",
    "    --language_pairs en-cs,cs-en \\\n",
    "    --mmt_data_path placeholder \\\n",
    "    --override_test_data_path haoranxu/WMT23-Test \\\n",
    "    --per_device_eval_batch_size 1 \\\n",
    "    --output_dir ./outputs/unpretrained \\\n",
    "    --predict_with_generate \\\n",
    "    --max_new_tokens 256 \\\n",
    "    --max_source_length 256 \\\n",
    "    --bf16 \\\n",
    "    --seed 42 \\\n",
    "    --num_beams 5 \\\n",
    "    --overwrite_cache \\\n",
    "    --overwrite_output_dir \\\n",
    "    --chat_style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307917e3",
   "metadata": {},
   "source": [
    "## Experiment 2: Pretrained Base (Normal X-ALMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d23f164",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run with pretrained base (ALMA-13B-Pretrain)\n",
    "!accelerate launch --config_file configs/deepspeed_eval_config_bf16.yaml \\\n",
    "    run_llmmt.py \\\n",
    "    --model_name_or_path haoranxu/X-ALMA-13B-Group5 \\\n",
    "    --custom_base_model haoranxu/ALMA-13B-Pretrain \\\n",
    "    --do_predict \\\n",
    "    --low_cpu_mem_usage \\\n",
    "    --language_pairs en-cs,cs-en \\\n",
    "    --mmt_data_path placeholder \\\n",
    "    --override_test_data_path haoranxu/WMT23-Test \\\n",
    "    --per_device_eval_batch_size 1 \\\n",
    "    --output_dir ./outputs/pretrained \\\n",
    "    --predict_with_generate \\\n",
    "    --max_new_tokens 256 \\\n",
    "    --max_source_length 256 \\\n",
    "    --bf16 \\\n",
    "    --seed 42 \\\n",
    "    --num_beams 5 \\\n",
    "    --overwrite_cache \\\n",
    "    --overwrite_output_dir \\\n",
    "    --chat_style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86346d32",
   "metadata": {},
   "source": [
    "## View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1596f9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample translations - Czech to English\n",
    "print(\"=\" * 80)\n",
    "print(\"UNPRETRAINED BASE - Czech to English (First 10)\")\n",
    "print(\"=\" * 80)\n",
    "with open('./outputs/unpretrained/test-cs-en.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for i, line in enumerate(lines[:10], 1):\n",
    "        print(f\"{i}. {line.strip()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PRETRAINED BASE - Czech to English (First 10)\")\n",
    "print(\"=\" * 80)\n",
    "with open('./outputs/pretrained/test-cs-en.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for i, line in enumerate(lines[:10], 1):\n",
    "        print(f\"{i}. {line.strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f67fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample translations - English to Czech\n",
    "print(\"=\" * 80)\n",
    "print(\"UNPRETRAINED BASE - English to Czech (First 10)\")\n",
    "print(\"=\" * 80)\n",
    "with open('./outputs/unpretrained/test-en-cs.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for i, line in enumerate(lines[:10], 1):\n",
    "        print(f\"{i}. {line.strip()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PRETRAINED BASE - English to Czech (First 10)\")\n",
    "print(\"=\" * 80)\n",
    "with open('./outputs/pretrained/test-en-cs.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for i, line in enumerate(lines[:10], 1):\n",
    "        print(f\"{i}. {line.strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dada80a",
   "metadata": {},
   "source": [
    "## Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fa3707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create zip file with all results\n",
    "!zip -r ablation_results.zip outputs/\n",
    "\n",
    "# Download link will appear in output\n",
    "from IPython.display import FileLink\n",
    "FileLink('ablation_results.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8608ccb9",
   "metadata": {},
   "source": [
    "## Quick Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b0544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count lines and show statistics\n",
    "import os\n",
    "\n",
    "def count_lines(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        return len(f.readlines())\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"EXPERIMENT SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nUnpretrained Base (meta-llama/Llama-2-13b-hf):\")\n",
    "print(f\"  - cs→en translations: {count_lines('./outputs/unpretrained/test-cs-en.txt')}\")\n",
    "print(f\"  - en→cs translations: {count_lines('./outputs/unpretrained/test-en-cs.txt')}\")\n",
    "\n",
    "print(f\"\\nPretrained Base (haoranxu/ALMA-13B-Pretrain):\")\n",
    "print(f\"  - cs→en translations: {count_lines('./outputs/pretrained/test-cs-en.txt')}\")\n",
    "print(f\"  - en→cs translations: {count_lines('./outputs/pretrained/test-en-cs.txt')}\")\n",
    "\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Download the results.zip file\")\n",
    "print(\"2. Calculate BLEU/COMET scores with reference translations\")\n",
    "print(\"3. Compare the scores to measure pretrain contribution\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
